{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jewish-respect",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: keras in ./venv/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./venv/lib/python3.9/site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in ./venv/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in ./venv/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./venv/lib/python3.9/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from tensorflow) (60.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in ./venv/lib/python3.9/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./venv/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./venv/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./venv/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas tensorflow keras tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-expansion",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "expensive-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_train = pd.read_csv('data/TIMIT/train.mfcccsv').values\n",
    "mfcc_test = pd.read_csv('data/TIMIT/test.mfcccsv').values\n",
    "y_train = pd.read_csv('data/TIMIT/train.targcsv').values\n",
    "y_test = pd.read_csv('data/TIMIT/test.targcsv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "surface-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 3000 samples, test on 800 samples\n"
     ]
    }
   ],
   "source": [
    "# we only use a random sample of the data\n",
    "sample_idx = np.random.choice(np.arange(mfcc_train.shape[0]), 3000, replace=False)\n",
    "mfcc_train = mfcc_train[sample_idx]\n",
    "y_train = y_train[sample_idx]\n",
    "\n",
    "sample_idx = np.random.choice(np.arange(mfcc_train.shape[0]), 800, replace=False)\n",
    "mfcc_test = mfcc_test[sample_idx]\n",
    "y_test = y_test[sample_idx]\n",
    "print(\"train on {} samples, test on {} samples\".format(mfcc_train.shape[0], mfcc_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "least-boating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 13), (3000, 40), (800, 13), (800, 40))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_train.shape, y_train.shape, mfcc_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "employed-yahoo",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def euclidian_distance(vec1, vec2):\n",
    "    \"\"\" return euclidian distance between two vectors \"\"\"\n",
    "    return np.sqrt( np.sum( (vec1 - vec2) **2 , axis=0) )\n",
    "    \n",
    "class KNearestNeighbor:\n",
    "    # contains indices of 200 nearest neighbors for each test sample\n",
    "    nearest_neighbors = [] # np array shape (num_test_samples, 200)\n",
    "    \n",
    "    def store_nn(self, X_train, X_test, y_train, y_test):\n",
    "        # store 200 nearest neighbors for each item in X_test\n",
    "        distances = [] # list of tuples (index)\n",
    "        for _test_sample in tqdm(X_test):\n",
    "            \n",
    "            _distances_row = [euclidian_distance(_test_sample, _train_sample) for _train_sample in X_train]\n",
    "            _distances_row = np.array(_distances_row)\n",
    "            \n",
    "            _nn_train_indices = np.argsort(_distances_row)[0:200]\n",
    "            _nn_labels = np.argmax( y_train[ _nn_train_indices ], axis=1)\n",
    "            \n",
    "            self.nearest_neighbors.append(_nn_labels)\n",
    "        \n",
    "        self.nearest_neighbors = np.vstack ( self.nearest_neighbors)\n",
    "        print(self.nearest_neighbors.shape)\n",
    "                \n",
    "    def predict(self, X, k=3):\n",
    "        preds = []\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            neighbors = self.nearest_neighbors[i, 0:k] # get relevant neighbors\n",
    "            counts = np.bincount(neighbors)\n",
    "            prediction = np.argmax(counts) # set prediction to most common label value\n",
    "            preds.append(prediction)\n",
    "            \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestNeighbor()\n",
    "knn.store_nn(mfcc_train, mfcc_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "embedded-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1: prediction rate = 41.62\n",
      "k=3: prediction rate = 44.38\n",
      "k=5: prediction rate = 48.88\n",
      "k=7: prediction rate = 50.88\n",
      "k=9: prediction rate = 51.38\n",
      "k=11: prediction rate = 51.75\n",
      "k=13: prediction rate = 51.50\n",
      "k=15: prediction rate = 52.00\n"
     ]
    }
   ],
   "source": [
    "def get_prediction_rate(y_pred, y_test):\n",
    "    return np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "k_values_to_try = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "for _k in k_values_to_try:\n",
    "    preds = knn.predict(mfcc_test, k=_k)\n",
    "    prediction_rate = get_prediction_rate(np.array(preds), np.argmax(y_test, axis=1))\n",
    "    print(\"k={}: prediction rate = {:.2f}\".format(_k, prediction_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-watch",
   "metadata": {},
   "source": [
    "## b) Normalized feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "third-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 800/800 [00:35<00:00, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mfcc_train_norm = ( mfcc_train - np.mean(mfcc_train, axis=0) ) / np.std(mfcc_train, axis=0)\n",
    "mfcc_test_norm = ( mfcc_test - np.mean(mfcc_test, axis=0) ) / np.std(mfcc_test, axis=0)\n",
    "\n",
    "knn_norm = KNearestNeighbor()\n",
    "knn_norm.store_nn(mfcc_train_norm, mfcc_test_norm, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "broken-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1: prediction rate = 43.50\n",
      "k=3: prediction rate = 46.12\n",
      "k=5: prediction rate = 49.50\n",
      "k=7: prediction rate = 50.62\n",
      "k=9: prediction rate = 52.00\n",
      "k=11: prediction rate = 53.62\n",
      "k=13: prediction rate = 53.50\n",
      "k=15: prediction rate = 54.62\n"
     ]
    }
   ],
   "source": [
    "for _k in k_values_to_try:\n",
    "    preds = knn_norm.predict(mfcc_test, k=_k)\n",
    "    prediction_rate = get_prediction_rate(np.array(preds), np.argmax(y_test, axis=1))\n",
    "    print(\"k={}: prediction rate = {:.2f}\".format(_k, prediction_rate*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-exercise",
   "language": "python",
   "name": "asr-exercise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
